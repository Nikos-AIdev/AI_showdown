{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQqYgGVYnhco"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade transformers==4.56.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2aO6PbB0WU3"
      },
      "outputs": [],
      "source": [
        "# Let's check the GPU - it should be a Tesla T4\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "  if gpu_info.find('Tesla T4') >= 0:\n",
        "    print(\"Success - Connected to a T4\")\n",
        "  else:\n",
        "    print(\"NOT CONNECTED TO A T4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZR-wgFH-CKtO"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jTthxWyAJJZ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "prompt = \"A class of students learning AI engineering in a vibrant pop-art style\"\n",
        "image = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0.0).images[0]\n",
        "display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAeRMxVdJMDF"
      },
      "outputs": [],
      "source": [
        "# Restart the kernel\n",
        "\n",
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UubQ06ZvEOj-"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A class of data scientists learning AI engineering in a vibrant high-energy pop-art style\"\n",
        "\n",
        "image = pipe(prompt=prompt, num_inference_steps=30).images[0]\n",
        "\n",
        "display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeE9YBDoXyvi"
      },
      "outputs": [],
      "source": [
        "# Restart the kernel\n",
        "\n",
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmijo03lNsCC"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "base = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True)\n",
        "base.to(\"cuda\")\n",
        "refiner = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\", text_encoder_2=base.text_encoder_2, vae=base.vae, torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\",)\n",
        "refiner.to(\"cuda\")\n",
        "\n",
        "# Define how many steps and what % of steps to be run on each experts (80/20) here\n",
        "n_steps = 40\n",
        "high_noise_frac = 0.8\n",
        "\n",
        "prompt = \"A class of data scientists learning AI engineering in a vibrant high-energy pop-art style\"\n",
        "\n",
        "# run both experts\n",
        "image = base(\n",
        "    prompt=prompt,\n",
        "    num_inference_steps=n_steps,\n",
        "    denoising_end=high_noise_frac,\n",
        "    output_type=\"latent\",\n",
        ").images\n",
        "\n",
        "image = refiner(\n",
        "    prompt=prompt,\n",
        "    num_inference_steps=n_steps,\n",
        "    denoising_start=high_noise_frac,\n",
        "    image=image,\n",
        ").images[0]\n",
        "\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEQ2eeW7Kaxu"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYqEcdsPxmBh"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade datasets==3.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5G9d2XLNo1Z"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from IPython.display import Audio\n",
        "\n",
        "synthesiser = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\", device='cuda')\n",
        "embeddings_dataset = load_dataset(\"matthijs/cmu-arctic-xvectors\", split=\"validation\", trust_remote_code=True)\n",
        "speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "speech = synthesiser(\"Hi to an artificial intelligence engineer, on the way to mastery!\", forward_params={\"speaker_embeddings\": speaker_embedding})\n",
        "\n",
        "Audio(speech[\"audio\"], rate=speech[\"sampling_rate\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Vk0La6POTcT"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv1Iv0vjPlI5"
      },
      "source": [
        "## This next cells will only work on a powerful GPU box like an A100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYoVlIwb5YEL"
      },
      "outputs": [],
      "source": [
        "# Let's check the GPU - it should be an A100\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "  if gpu_info.find('A100') >= 0:\n",
        "    print(\"Success - Connected to an NVIDIA A100\")\n",
        "  else:\n",
        "    print(\"NOT CONNECTED TO AN A100\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw_WV7SgTWBv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import FluxPipeline\n",
        "from IPython.display import display\n",
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16).to(\"cuda\")\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(0)\n",
        "prompt = \"A class of data scientists learning AI engineering in a vibrant high-energy pop-art style\"\n",
        "\n",
        "# Generate the image using the GPU\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    guidance_scale=0.0,\n",
        "    num_inference_steps=4,\n",
        "    max_sequence_length=256,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "display(image)\n",
        "\n",
        "stop = datetime.now()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE7Fcljg56x1"
      },
      "outputs": [],
      "source": [
        "# Cost estimate\n",
        "\n",
        "seconds = (stop-start).total_seconds()\n",
        "units_per_hour = 5.37\n",
        "estimated_units = (5.37 / 3600) * seconds\n",
        "estimated_cost = estimated_units * (9.99/100)\n",
        "print(f\"This took {seconds:.1f} seconds and cost an estimated ${estimated_cost:.3f}\")\n",
        "\n",
        "# But there's a catch - you pay for all the time the kernel is active, not just while it's actually calculating!\n",
        "# So remember to shut down a Paid kernel.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ysVs1HD0yyD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
