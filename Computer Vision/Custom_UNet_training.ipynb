{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-IYmj1pAmfz",
        "outputId": "69ae0d40-5a01-4a2f-a862-459b6910544b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Human-Segmentation-Dataset'...\n",
            "remote: Enumerating objects: 596, done.\u001b[K\n",
            "remote: Total 596 (delta 0), reused 0 (delta 0), pack-reused 596 (from 1)\u001b[K\n",
            "Receiving objects: 100% (596/596), 13.60 MiB | 43.79 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/VikramShenoy97/Human-Segmentation-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import Adam, AdamW, SGD"
      ],
      "metadata": {
        "id": "r2qe9j7DCx2c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, image_dir, mask_dir):\n",
        "    self.image_dir = image_dir\n",
        "    self.mask_dir = mask_dir\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.Resize((512,512)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    valid_extension = {\".jpg\", \".jpeg\", \".png\"}\n",
        "    self.images = [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in valid_extension]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "    name, ext = os.path.splitext(self.images[idx])\n",
        "    mask_path = os.path.join(self.mask_dir, f\"{name}.png\")\n",
        "\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "    image = self.transform(image)\n",
        "    mask = self.transform(mask)\n",
        "\n",
        "    mask = (mask > 0.5).float()\n",
        "\n",
        "    return image, mask"
      ],
      "metadata": {
        "id": "mDuQeYjfFvj5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(image_dir, mask_dir, batch_size=2, shuffle=True):\n",
        "  dataset = SegmentationDataset(image_dir, mask_dir)\n",
        "  return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
      ],
      "metadata": {
        "id": "9PHsZzyrSP_r"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv_op = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv_op(x)"
      ],
      "metadata": {
        "id": "vbRgXoswTM0v"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv = DoubleConv(in_channels, out_channels)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    down = self.conv(x)\n",
        "    p = self.pool(down)\n",
        "\n",
        "    return down, p"
      ],
      "metadata": {
        "id": "ogQt2ibXVKC7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
        "    self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x1 = self.up(x1)\n",
        "    x = torch.cat([x2, x1], dim=1)\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "DOpVN9bqW8dq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super().__init__()\n",
        "    self.down_convolution_1 = DownSample(in_channels, 64)\n",
        "    self.down_convolution_2 = DownSample(64, 128)\n",
        "    self.down_convolution_3 = DownSample(128, 256)\n",
        "    self.down_convolution_4 = DownSample(256, 512)\n",
        "\n",
        "    self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "    self.up_convolution_1 = UpSample(1024, 512)\n",
        "    self.up_convolution_2 = UpSample(512, 256)\n",
        "    self.up_convolution_3 = UpSample(256, 128)\n",
        "    self.up_convolution_4 = UpSample(128, 64)\n",
        "\n",
        "    self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    down_1, p1 = self.down_convolution_1(x)\n",
        "    down_2, p2 = self.down_convolution_2(p1)\n",
        "    down_3, p3 = self.down_convolution_3(p2)\n",
        "    down_4, p4 = self.down_convolution_4(p3)\n",
        "\n",
        "    b = self.bottle_neck(p4)\n",
        "\n",
        "    up_1 = self.up_convolution_1(b, down_4)\n",
        "    up_2 = self.up_convolution_2(up_1, down_3)\n",
        "    up_3 = self.up_convolution_3(up_2, down_2)\n",
        "    up_4 = self.up_convolution_4(up_3, down_1)\n",
        "\n",
        "    out = self.out(up_4)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "0_TFLfb3WyNS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self, smooth=1e-6):\n",
        "    super(DiceLoss, self).__init__()\n",
        "    self.smooth = smooth\n",
        "\n",
        "  def forward(self, inputs, targets):\n",
        "    inputs = inputs.view(-1)\n",
        "    targets = targets.view(-1)\n",
        "    intersection = (inputs * targets).sum()\n",
        "    dice_score = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
        "\n",
        "    return 1 - dice_score"
      ],
      "metadata": {
        "id": "TGIkcmLBe2jc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCEWithDiceLoss(nn.Module):\n",
        "  def __init__(self, smooth=1e-6):\n",
        "    super(BCEWithDiceLoss, self).__init__()\n",
        "    self.bce = nn.BCEWithLogitsLoss()\n",
        "    self.dice = DiceLoss(smooth)\n",
        "\n",
        "  def forward(self, inputs, targets):\n",
        "    bce_loss = self.bce(inputs, targets)\n",
        "    dice_loss = self.dice(inputs, targets)\n",
        "\n",
        "    return bce_loss + dice_loss"
      ],
      "metadata": {
        "id": "tjbRAJe1jp_R"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Loop\n",
        "\n",
        "def train(model, dataloader, epochs=2, lr=0.001, save_path=\"unet_model\", load_path=None):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  if load_path and os.path.exists(load_path):\n",
        "    print(f\"Loading model weights from {load_path}\")\n",
        "    model.load_state_dict(torch.load(load_path), map_location=device)\n",
        "  else:\n",
        "    print(f\"No previous model found, training from scratch\")\n",
        "\n",
        "  print(device)\n",
        "  model.to(device)\n",
        "\n",
        "  criterion = BCEWithDiceLoss()\n",
        "  optimizer = SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for images, masks in dataloader:\n",
        "      images = images.to(device)\n",
        "      masks = masks.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(images)\n",
        "\n",
        "      loss = criterion(output, masks)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    #save every 10th epoch\n",
        "    if epoch % 10 == 0 and epoch > 0:\n",
        "      torch.save(model.state_dict(), f\"{save_path}.pth\")\n",
        "\n",
        "  #Save final\n",
        "  torch.save(model.state_dict(), f\"{save_path}_final.pth\")\n",
        "  print(f\"Model Saved to {save_path}\")"
      ],
      "metadata": {
        "id": "7gzBU7AYknG9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Starting..\n",
        "dataloader = get_dataloader(\"/content/Human-Segmentation-Dataset/Training_Images\", \"/content/Human-Segmentation-Dataset/Ground_Truth\", batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "ddcroiZzrtAb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(in_channels=3, num_classes=1)"
      ],
      "metadata": {
        "id": "mocbFwNus_PF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, dataloader, epochs=50, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTGrbUOBvsd7",
        "outputId": "b7b1592f-d328-4759-8264-0795d7cecdc3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No previous model found, training from scratch\n",
            "cuda\n",
            "Epoch 1/50, Loss: 1.5347\n",
            "Epoch 2/50, Loss: 1.5191\n",
            "Epoch 3/50, Loss: 1.5144\n",
            "Epoch 4/50, Loss: 1.5034\n",
            "Epoch 5/50, Loss: 1.4972\n",
            "Epoch 6/50, Loss: 1.4970\n",
            "Epoch 7/50, Loss: 1.4876\n",
            "Epoch 8/50, Loss: 1.4836\n",
            "Epoch 9/50, Loss: 1.4904\n",
            "Epoch 10/50, Loss: 1.4823\n",
            "Epoch 11/50, Loss: 1.4810\n",
            "Epoch 12/50, Loss: 1.4827\n",
            "Epoch 13/50, Loss: 1.4798\n",
            "Epoch 14/50, Loss: 1.4793\n",
            "Epoch 15/50, Loss: 1.4771\n",
            "Epoch 16/50, Loss: 1.4770\n",
            "Epoch 17/50, Loss: 1.4773\n",
            "Epoch 18/50, Loss: 1.4786\n",
            "Epoch 19/50, Loss: 1.4775\n",
            "Epoch 20/50, Loss: 1.4712\n",
            "Epoch 21/50, Loss: 1.4703\n",
            "Epoch 22/50, Loss: 1.4702\n",
            "Epoch 23/50, Loss: 1.4712\n",
            "Epoch 24/50, Loss: 1.4734\n",
            "Epoch 25/50, Loss: 1.4664\n",
            "Epoch 26/50, Loss: 1.4690\n",
            "Epoch 27/50, Loss: 1.4749\n",
            "Epoch 28/50, Loss: 1.4689\n",
            "Epoch 29/50, Loss: 1.4685\n",
            "Epoch 30/50, Loss: 1.4728\n",
            "Epoch 31/50, Loss: 1.4774\n",
            "Epoch 32/50, Loss: 1.4707\n",
            "Epoch 33/50, Loss: 1.4662\n",
            "Epoch 34/50, Loss: 1.4678\n",
            "Epoch 35/50, Loss: 1.4743\n",
            "Epoch 36/50, Loss: 1.4717\n",
            "Epoch 37/50, Loss: 1.4729\n",
            "Epoch 38/50, Loss: 1.4676\n",
            "Epoch 39/50, Loss: 1.4617\n",
            "Epoch 40/50, Loss: 1.4643\n",
            "Epoch 41/50, Loss: 1.4655\n",
            "Epoch 42/50, Loss: 1.4680\n",
            "Epoch 43/50, Loss: 1.4645\n",
            "Epoch 44/50, Loss: 1.4649\n",
            "Epoch 45/50, Loss: 1.4625\n",
            "Epoch 46/50, Loss: 1.4687\n",
            "Epoch 47/50, Loss: 1.4633\n",
            "Epoch 48/50, Loss: 1.4600\n",
            "Epoch 49/50, Loss: 1.4594\n",
            "Epoch 50/50, Loss: 1.4634\n",
            "Model Saved to unet_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference on trained model\n",
        "import numpy as np\n",
        "\n",
        "#Load model and predict with stats\n",
        "def predict(model_path, input_image_path):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  #Load model\n",
        "  model = UNet(in_channels=3, num_classes=1)\n",
        "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  #Track start time\n",
        "  total_start_time = time.time()\n",
        "\n",
        "  #Image preprocessing\n",
        "  preprocess_start_time = time.time()\n",
        "  image = Image.open(input_image_path).convert(\"RGB\")\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((512,512)),\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "  image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "  preprocess_end_time = time.time()\n",
        "\n",
        "  #Model Inference\n",
        "  inference_start_time = time.time()\n",
        "  with torch.no_grad():\n",
        "    output = model(image_tensor)\n",
        "    output = torch.sigmoid(output)\n",
        "  inference_end_time = time.time()\n",
        "\n",
        "  #Postprocessing\n",
        "  postprocess_start_time = time.time()\n",
        "  mask = output.squeeze(0).squeeze(0).cpu().numpy()\n",
        "  mask = (mask > 0.4).astype(np.uint8) * 255\n",
        "  mask_image = Image.fromarray(mask)\n",
        "\n",
        "  combined = Image.new(\"RGB\", (512*2, 512))\n",
        "  combined.paste(image.resize((512,512)), (0,0))\n",
        "  combined.paste(mask_image.convert(\"RGB\"), (512,0))\n",
        "  combined.save(\"output.jpg\")\n",
        "  postprocess_end_time = time.time()\n",
        "\n",
        "  #Calculate timing stats\n",
        "  total_end_time = time.time()\n",
        "\n",
        "  preprocess_time = preprocess_end_time - preprocess_start_time\n",
        "  inference_time = inference_end_time - inference_start_time\n",
        "  postprocess_time = postprocess_end_time - postprocess_start_time\n",
        "  total_time = total_end_time - total_start_time\n",
        "\n",
        "  #Print Stats\n",
        "  print(\"Prediction Completed! Some Stats:\")\n",
        "  print(f\"Image Preprocessing Time: {preprocess_time:.4f} seconds\")\n",
        "  print(f\"Model Inference Time: {inference_time:.4f} seconds\")\n",
        "  print(f\"Postprocessing Time: {postprocess_time:.4f} seconds\")\n",
        "  print(f\"Total Prediction Time: {total_time:.4f} seconds\")\n",
        "  print(\"Prediction saved as output.jpg\")"
      ],
      "metadata": {
        "id": "5dNkro3ewAmC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"/content/unet_model_final.pth\", \"/content/Human-Segmentation-Dataset/Training_Images/104.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLaI8eGw-6IA",
        "outputId": "97c70ac2-236f-4f07-9040-aa0b9511f7be"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Prediction Completed! Some Stats:\n",
            "Image Preprocessing Time: 0.0085 seconds\n",
            "Model Inference Time: 0.0034 seconds\n",
            "Postprocessing Time: 0.1182 seconds\n",
            "Total Prediction Time: 0.1300 seconds\n",
            "Prediction saved as output.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sgXjvFwF_EKY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}